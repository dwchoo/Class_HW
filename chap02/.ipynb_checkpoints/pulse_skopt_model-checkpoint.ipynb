{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "import skopt\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence, plot_objective, plot_evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_min_max(loss):\n",
    "    if math.isnan(loss):\n",
    "        loss = 1e+5\n",
    "    else:\n",
    "        loss = min(float(loss), 1e+5)\n",
    "        loss = max(float(loss), 1e-10)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pulsar_dataset(adjust_ratio):\n",
    "    pulsars, stars = [], []\n",
    "    with open('../../data/chap02/pulsar_stars.csv') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader, None)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            if row[8] == '1': pulsars.append(row)\n",
    "            else: stars.append(row)\n",
    "            \n",
    "    global data, input_cnt, output_cnt\n",
    "    input_cnt, output_cnt = 8, 1\n",
    "    \n",
    "    star_cnt, pulsar_cnt = len(stars), len(pulsars)\n",
    "\n",
    "    if adjust_ratio:\n",
    "        data = np.zeros([2*star_cnt, 9])\n",
    "        data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "        for n in range(star_cnt):\n",
    "            data[star_cnt+n] = np.asarray(pulsars[n % pulsar_cnt], dtype='float32')\n",
    "    else:\n",
    "        data = np.zeros([star_cnt+pulsar_cnt, 9])\n",
    "        data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "        data[star_cnt:, :] = np.asarray(pulsars, dtype='float32')\n",
    "    x = data[:,:8]\n",
    "    y = data[:,8]\n",
    "    return x, y\n",
    "\n",
    "def eval_accuracy(output, y):\n",
    "    est_yes = np.greater(output, 0.5).reshape(-1,)\n",
    "    ans_yes = np.greater(y, 0.5).reshape(-1,)\n",
    "    est_no = np.logical_not(est_yes)\n",
    "    ans_no = np.logical_not(ans_yes)\n",
    "    \n",
    "    tp = np.sum(np.logical_and(est_yes, ans_yes))\n",
    "    fp = np.sum(np.logical_and(est_yes, ans_no))\n",
    "    fn = np.sum(np.logical_and(est_no, ans_yes))\n",
    "    tn = np.sum(np.logical_and(est_no, ans_no))\n",
    "    \n",
    "    accuracy = safe_div(tp+tn, tp+tn+fp+fn)\n",
    "    precision = safe_div(tp, tp+fp)\n",
    "    recall = safe_div(tp, tp+fn)\n",
    "    f1 = 2 * safe_div(recall*precision, recall+precision)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1]\n",
    "\n",
    "def safe_div(p, q):\n",
    "    p, q = float(p), float(q)\n",
    "    if np.abs(q) < 1.0e-20: return np.sign(p)\n",
    "    return p / q\n",
    "\n",
    "def kfold_data(data):\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    kf.get_n_splits(data)\n",
    "    kfold_data = {}\n",
    "    for index, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "        train_data = data[train_index]\n",
    "        test_data = data[test_index]\n",
    "        kfold_data[index] = {'train' : train_data, 'test' : test_data}\n",
    "    return kfold_data\n",
    "\n",
    "def kfold_return_train(n_fold, kfold_data):\n",
    "    output_cnt = 8\n",
    "    if n_fold not in range(10):\n",
    "        print('{} is not in range(10)'.format(n_fold))\n",
    "        raise NameError('Change n_fold')\n",
    "    train_data = kfold_data[n_fold]['train']\n",
    "    #test_data = kfold_data[n_fold]['test']\n",
    "    train_data_input = train_data[:, :-output_cnt]\n",
    "    train_data_output = train_data[:, -output_cnt:]\n",
    "    return [train_data_input, train_data_output]\n",
    "def kfold_return_test(n_fold, kfold_data):\n",
    "    output_cnt = 8\n",
    "    if n_fold not in range(10):\n",
    "        print('{} is not in range(10)'.format(n_fold))\n",
    "        raise NameError('Change n_fold')\n",
    "    #train_data = kfold_data[n_fold]['train']\n",
    "    test_data = kfold_data[n_fold]['test']\n",
    "    test_data_input = test_data[:, :-output_cnt]\n",
    "    test_data_output = test_data[:, -output_cnt:]\n",
    "    return [test_data_input, test_data_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pulse_model:\n",
    "    def __init__(self,learning_rate = 0.01,n_fold = None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self.define_model()\n",
    "        \n",
    "    def init_data(self, train_data, test_data):\n",
    "        self.X_train = train_data[0]\n",
    "        self.Y_train = train_data[1]\n",
    "        self.X_test = test_data[0]\n",
    "        self.Y_test = test_data[1]\n",
    "        \n",
    "    def define_model(self,verbose = 0):\n",
    "        x = Input(shape=(8))\n",
    "        y = Dense(1, activation='sigmoid')(x)\n",
    "        __model = Model(x, y)\n",
    "        if verbose is not 0: __model.summary()\n",
    "        return __model\n",
    "    \n",
    "    def model_compile(self):\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                           metrics=['accuracy']\n",
    "                          )\n",
    "    \n",
    "    def model_fit(self,verbose = 0):\n",
    "        self.model.fit(x = self.X_train, y = self.Y_train,\n",
    "                       validation_data = (self.X_test, self.Y_test),\n",
    "                       batch_size = 64,\n",
    "                       epochs = 10,\n",
    "                       verbose = verbose\n",
    "                      )\n",
    "        \n",
    "    def model_evaluate(self,verbose=0):\n",
    "        output = self.model.predict(self.X_test,verbose=verbose)\n",
    "        test_loss, test_acc = self.model.evaluate(self.X_test, self.Y_test,verbose=verbose)\n",
    "        \n",
    "        result = self.eval_accuracy(output = output, y = self.Y_test)\n",
    "        #[accuracy, precision, recall, f1]\n",
    "        \n",
    "        if verbose is not 0:\n",
    "            print(\"acc: {:2.4f}, precis: {:2.4f}, recall: {:2.4f}, f1: {:2.4f}\".format(*result))\n",
    "        \n",
    "        result_dict = {'acc' : result[0], 'precis' : result[1],\n",
    "                       'recall' : result[2], 'f1' : result[3],\n",
    "                       'loss' : test_loss\n",
    "                      }\n",
    "        return result_dict\n",
    "        \n",
    "        \n",
    "    def eval_accuracy(self,output, y):\n",
    "        est_yes = np.greater(output, 0.5).reshape(-1,)\n",
    "        ans_yes = np.greater(y, 0.5).reshape(-1,)\n",
    "        est_no = np.logical_not(est_yes)\n",
    "        ans_no = np.logical_not(ans_yes)\n",
    "\n",
    "        tp = np.sum(np.logical_and(est_yes, ans_yes))\n",
    "        fp = np.sum(np.logical_and(est_yes, ans_no))\n",
    "        fn = np.sum(np.logical_and(est_no, ans_yes))\n",
    "        tn = np.sum(np.logical_and(est_no, ans_no))\n",
    "\n",
    "        accuracy = self.safe_div(tp+tn, tp+tn+fp+fn)\n",
    "        precision = self.safe_div(tp, tp+fp)\n",
    "        recall = self.safe_div(tp, tp+fn)\n",
    "        f1 = 2 * self.safe_div(recall*precision, recall+precision)\n",
    "\n",
    "        return [accuracy, precision, recall, f1]\n",
    "\n",
    "    def safe_div(self,p, q):\n",
    "        p, q = float(p), float(q)\n",
    "        if np.abs(q) < 1.0e-20: return np.sign(p)\n",
    "        return p / q\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_test = pulse_model()\n",
    "X, Y = load_pulsar_dataset(True)\n",
    "test_train_split = -1000\n",
    "X_train = X[:test_train_split]\n",
    "Y_train = Y[:test_train_split]\n",
    "X_test = X[test_train_split:]\n",
    "Y_test = Y[test_train_split:]\n",
    "model_test.init_data(train_data=[X_train, Y_train], test_data=[X_test,Y_test])\n",
    "model_test.model_compile()\n",
    "model_test.model_fit(verbose=1)\n",
    "result = model_test.model_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pulse_model_optimize:\n",
    "    def __init__(self,learning_rate = 0.01,adjust_ratio=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        \n",
    "        raw_data = self.load_pulsar_dataset(adjust_ratio)\n",
    "        self._kfold_data = self.kfold_data(raw_data)\n",
    "        \n",
    "        \n",
    "    def model_trainning(self, train_data, test_data, proc_num=None, return_dict = None):\n",
    "        model_init = pulse_model(learning_rate=self.learning_rate)\n",
    "        model_init.init_data(train_data = train_data,\n",
    "                             test_data = test_data)\n",
    "        model_init.model_compile()\n",
    "        model_init.model_fit(verbose=0)\n",
    "        model_result_dict = model_init.model_evaluate(verbose=0)\n",
    "        \n",
    "        if proc_num is not None and return_dict is not None:\n",
    "            return_dict[proc_num] = model_result_dict\n",
    "\n",
    "        return model_result_dict\n",
    "        \n",
    "    def model_train_multiprocess(self,):\n",
    "        kfold_data_set = []\n",
    "        for index in range(10):\n",
    "            train_data = self.kfold_return_train(n_fold=index, kfold_data=self._kfold_data)\n",
    "            test_data = self.kfold_return_test(n_fold=index, kfold_data=self._kfold_data)\n",
    "            kfold_data_set.append((train_data, test_data))\n",
    "            \n",
    "        manager = Manager()\n",
    "        return_dict = manager.dict()\n",
    "        \n",
    "        procs = []\n",
    "        for index, (train_data, test_data) in enumerate(kfold_data_set):\n",
    "            #print(train_data[0].shape, test_data[0].shape)\n",
    "            proc = Process(target=self.model_trainning,\n",
    "                           args=(train_data, test_data,\n",
    "                                 index, return_dict),\n",
    "                           name='{}-fold'.format(index)\n",
    "                          )\n",
    "            procs.append(proc)\n",
    "            proc.start()\n",
    "            \n",
    "        for proc in procs:\n",
    "            proc.join()\n",
    "            \n",
    "        return return_dict\n",
    "    \n",
    "    \n",
    "    def kfold_model_evaluate_result(self,return_dict, verbose = 0):\n",
    "        accuracies = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1s = []\n",
    "        losses = []\n",
    "        \n",
    "        for index in range(10):\n",
    "            acc     = return_dict[index]['acc']\n",
    "            prec    = return_dict[index]['precis']\n",
    "            recall  = return_dict[index]['recall']\n",
    "            f1      = return_dict[index]['f1']\n",
    "            loss    = return_dict[index]['loss']\n",
    "\n",
    "            accuracies.append(acc)\n",
    "            precisions.append(prec)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            losses.append(loss)\n",
    "            \n",
    "        mean_acc    = np.array(accuracies).mean()\n",
    "        mean_prec   = np.array(precisions).mean()\n",
    "        mean_recall = np.array(recalls).mean()\n",
    "        mean_f1     = np.array(f1s).mean()\n",
    "        \n",
    "        mean_loss = np.array(losses).mean()\n",
    "        \n",
    "        return_result_list = [mean_acc, mean_prec, mean_recall, mean_f1, mean_loss]\n",
    "        #print(return_result_list)\n",
    "        if verbose is not 0:\n",
    "            print(\"acc: {:2.4f}, precis: {:2.4f}, recall: {:2.4f}, f1: {:2.4f}, loss: {:2.4f}\".format(*return_result_list))\n",
    "        \n",
    "\n",
    "        return return_result_list\n",
    "        \n",
    "        \n",
    "    \n",
    "    def load_pulsar_dataset(self,adjust_ratio):\n",
    "        pulsars, stars = [], []\n",
    "        with open('../../data/chap02/pulsar_stars.csv') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            next(csvreader, None)\n",
    "            rows = []\n",
    "            for row in csvreader:\n",
    "                if row[8] == '1': pulsars.append(row)\n",
    "                else: stars.append(row)\n",
    "\n",
    "        #global data, input_cnt, output_cnt\n",
    "        input_cnt, output_cnt = 8, 1\n",
    "\n",
    "        star_cnt, pulsar_cnt = len(stars), len(pulsars)\n",
    "\n",
    "        if adjust_ratio:\n",
    "            data = np.zeros([2*star_cnt, 9])\n",
    "            data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "            for n in range(star_cnt):\n",
    "                data[star_cnt+n] = np.asarray(pulsars[n % pulsar_cnt], dtype='float32')\n",
    "        else:\n",
    "            data = np.zeros([star_cnt+pulsar_cnt, 9])\n",
    "            data[0:star_cnt, :] = np.asarray(stars, dtype='float32')\n",
    "            data[star_cnt:, :] = np.asarray(pulsars, dtype='float32')\n",
    "        #x = data[:,:8]\n",
    "        #y = data[:,8]\n",
    "        return data\n",
    "    \n",
    "    def kfold_data(self, data):\n",
    "        import sklearn\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=10, shuffle=True)\n",
    "        kf.get_n_splits(data)\n",
    "        kfold_data = {}\n",
    "        for index, (train_index, test_index) in enumerate(kf.split(data)):\n",
    "            train_data = data[train_index]\n",
    "            test_data = data[test_index]\n",
    "            kfold_data[index] = {'train' : train_data, 'test' : test_data}\n",
    "        return kfold_data\n",
    "\n",
    "    def kfold_return_train(self, n_fold, kfold_data):\n",
    "        output_cnt = 1\n",
    "        if n_fold not in range(10):\n",
    "            print('{} is not in range(10)'.format(n_fold))\n",
    "            raise NameError('Change n_fold')\n",
    "        train_data = kfold_data[n_fold]['train']\n",
    "        #test_data = kfold_data[n_fold]['test']\n",
    "        train_data_input = train_data[:, :-output_cnt]\n",
    "        train_data_output = train_data[:, -output_cnt:]\n",
    "        return [train_data_input, train_data_output]\n",
    "    \n",
    "    def kfold_return_test(self, n_fold, kfold_data):\n",
    "        output_cnt = 1\n",
    "        if n_fold not in range(10):\n",
    "            print('{} is not in range(10)'.format(n_fold))\n",
    "            raise NameError('Change n_fold')\n",
    "        #train_data = kfold_data[n_fold]['train']\n",
    "        test_data = kfold_data[n_fold]['test']\n",
    "        test_data_input = test_data[:, :-output_cnt]\n",
    "        test_data_output = test_data[:, -output_cnt:]\n",
    "        return [test_data_input, test_data_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8057, precis: 0.8328, recall: 0.8826, f1: 0.8333, loss: 3.6401\n"
     ]
    }
   ],
   "source": [
    "kfold_trainning = pulse_model_optimize(adjust_ratio=True)\n",
    "result_dict = kfold_trainning.model_train_multiprocess()\n",
    "result =  kfold_trainning.kfold_model_evaluate_result(result_dict, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    'learning_rate' : 0.05\n",
    "}\n",
    "\n",
    "default_HP = list(hp_dict.values())\n",
    "\n",
    "def model_tunning(hp_list):\n",
    "    HP_list2dict = {\n",
    "    'LEARNING_RATE' : float(hp_list[0])\n",
    "    }\n",
    "    print(\"======================start trainning=======================\")\n",
    "    print(HP_list2dict.items())\n",
    "    print('\\n')\n",
    "    \n",
    "    tunning_model = pulse_model_optimize(learning_rate = hp_list[0],adjust_ratio=True)\n",
    "    result_dict = tunning_model.model_train_multiprocess()\n",
    "    result = tunning_model.kfold_model_evaluate_result(result_dict, verbose=1)\n",
    "    loss = result[-1]\n",
    "    \n",
    "\n",
    "    print('\\n')\n",
    "    print(\"======================end trainning=======================\")\n",
    "    return loss\n",
    "\n",
    "#dim_RND_MEAN_nodes = Integer(low=-100, high=100, name='RND_MEAN')\n",
    "#dim_RND_STD_nodes = Real(low=1e-8, high=1.0, prior='log-uniform', name='RND_STD')\n",
    "dim_learning_rate_nodes = Real(low=1e-6, high=1.0, prior='log-uniform',name='LEARNING_RATE')\n",
    "\n",
    "dimension_HP = [\n",
    "                #dim_RND_MEAN_nodes  ,\n",
    "                #dim_RND_STD_nodes  ,\n",
    "                dim_learning_rate_nodes\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "n_cell = 30\n",
    "n_random_starts = 10\n",
    "\n",
    "gp_fitting = gp_minimize(func=model_tunning,\n",
    "                        dimensions=dimension_HP,\n",
    "                        n_calls=n_cell,\n",
    "                        n_random_starts=n_random_starts,\n",
    "                        acq_func='EI',\n",
    "                        x0=default_HP\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_fitting.x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[0.00046039775275805785]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9214, precis: 0.9518, recall: 0.8883, f1: 0.9187, loss: 0.2187\n"
     ]
    }
   ],
   "source": [
    "kfold_trainning = pulse_model_optimize(learning_rate=0.0005813962134173598, adjust_ratio=True)\n",
    "result_dict = kfold_trainning.model_train_multiprocess()\n",
    "result =  kfold_trainning.kfold_model_evaluate_result(result_dict, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pulse_model_n_layer(pulse_model):\n",
    "    def __init__(self,learning_rate=0.01, layer_num = 1, n_unit = 32, n_fold=None):\n",
    "        self.layer_num = layer_num\n",
    "        self.n_unit = n_unit\n",
    "        super().__init__(learning_rate=learning_rate, n_fold=n_fold)\n",
    "        \n",
    "        \n",
    "    def define_model(self, verbose=0):\n",
    "        x = Input(shape=(8))\n",
    "        n_layer = x\n",
    "        for i in range(self.layer_num):\n",
    "            n_layer = Dense(self.n_unit, activation='relu')(n_layer)\n",
    "            \n",
    "        y = Dense(1, activation='sigmoid')(n_layer)\n",
    "        __model = Model(x,y)\n",
    "        if verbose is not 0: __model.summary()\n",
    "        return __model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_test = pulse_model_n_layer(layer_num=2, n_unit=20)\n",
    "X, Y = load_pulsar_dataset(True)\n",
    "test_train_split = -1000\n",
    "X_train = X[:test_train_split]\n",
    "Y_train = Y[:test_train_split]\n",
    "X_test = X[test_train_split:]\n",
    "Y_test = Y[test_train_split:]\n",
    "model_test.init_data(train_data=[X_train, Y_train], test_data=[X_test,Y_test])\n",
    "model_test.model_compile()\n",
    "model_test.model_fit(verbose=0)\n",
    "result = model_test.model_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pulse_model_n_layer_optimize(pulse_model_optimize):\n",
    "    def __init__(self, learning_rate=0.01, layer_num = 1, n_unit = 32, adjust_ratio=False):\n",
    "        self.layer_num = layer_num\n",
    "        self.n_unit = n_unit\n",
    "        super().__init__(learning_rate, adjust_ratio)\n",
    "        \n",
    "    def model_trainning(self, train_data, test_data, proc_num=None, return_dict = None):\n",
    "        model_init = pulse_model_n_layer(learning_rate=self.learning_rate,\n",
    "                                         layer_num=self.layer_num,\n",
    "                                         n_unit= self.n_unit,\n",
    "                                        )\n",
    "        model_init.init_data(train_data = train_data,\n",
    "                             test_data = test_data)\n",
    "        model_init.model_compile()\n",
    "        model_init.model_fit(verbose=0)\n",
    "        model_result_dict = model_init.model_evaluate(verbose=0)\n",
    "        \n",
    "        if proc_num is not None and return_dict is not None:\n",
    "            return_dict[proc_num] = model_result_dict\n",
    "\n",
    "        return model_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    'learning_rate' : 0.05,\n",
    "    'layer_num' : 1,\n",
    "    'n_unit' : 32\n",
    "}\n",
    "\n",
    "default_HP = list(hp_dict.values())\n",
    "\n",
    "def model_tunning(hp_list):\n",
    "    HP_list2dict = {\n",
    "        'LEARNING_RATE' : float(hp_list[0]),\n",
    "        'layer_num' : int(hp_list[1]),\n",
    "        'n_unit' : int(hp_list[2])\n",
    "    }\n",
    "    print(\"======================start trainning=======================\")\n",
    "    print(HP_list2dict.items())\n",
    "    print('\\n')\n",
    "    \n",
    "    tunning_model = pulse_model_n_layer_optimize(learning_rate = hp_list[0],\n",
    "                                                 layer_num=hp_list[1],\n",
    "                                                 n_unit=hp_list[2],\n",
    "                                                 adjust_ratio=True\n",
    "                                                )\n",
    "    result_dict = tunning_model.model_train_multiprocess()\n",
    "    result = tunning_model.kfold_model_evaluate_result(result_dict, verbose=1)\n",
    "    loss = result[-1]\n",
    "    \n",
    "    loss = loss_min_max(loss)\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"======================end trainning=======================\")\n",
    "    return loss\n",
    "\n",
    "#dim_RND_MEAN_nodes = Integer(low=-100, high=100, name='RND_MEAN')\n",
    "#dim_RND_STD_nodes = Real(low=1e-8, high=1.0, prior='log-uniform', name='RND_STD')\n",
    "dim_learning_rate_nodes = Real(low=1e-6, high=1.0, prior='log-uniform',name='LEARNING_RATE')\n",
    "dim_layer_num_nodes = Integer(low=0, high=5, name='layer_num')\n",
    "dim_n_unit_modes = Integer(low=1, high=1024, name='n_unit')\n",
    "\n",
    "dimension_HP = [\n",
    "                dim_learning_rate_nodes,\n",
    "                dim_layer_num_nodes,\n",
    "                dim_n_unit_modes,\n",
    "                ]\n",
    "\n",
    "\n",
    "\n",
    "n_cell = 40\n",
    "n_random_starts = 10\n",
    "\n",
    "gp_fitting_n_layer = gp_minimize(func=model_tunning,\n",
    "                        dimensions=dimension_HP,\n",
    "                        n_calls=n_cell,\n",
    "                        n_random_starts=n_random_starts,\n",
    "                        acq_func='EI',\n",
    "                        x0=default_HP\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer_hp = gp_fitting_n_layer.x\n",
    "n_layer_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer_hp = [6.221358238321396e-05, 2, 717]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = pulse_model_n_layer(learning_rate=n_layer_hp[0], layer_num=n_layer_hp[1], n_unit=n_layer_hp[2])\n",
    "X, Y = load_pulsar_dataset(True)\n",
    "test_train_split = -1000\n",
    "X_train = X[:test_train_split]\n",
    "Y_train = Y[:test_train_split]\n",
    "X_test = X[test_train_split:]\n",
    "Y_test = Y[test_train_split:]\n",
    "model_test.init_data(train_data=[X_train, Y_train], test_data=[X_test,Y_test])\n",
    "model_test.model_compile()\n",
    "model_test.model_fit(verbose=0)\n",
    "result = model_test.model_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9240, precis: 0.9530, recall: 0.8919, f1: 0.9214, loss: 0.2033\n"
     ]
    }
   ],
   "source": [
    "n_layer_hp = [6.221358238321396e-05, 2, 717]\n",
    "kfold_trainning = pulse_model_n_layer_optimize(learning_rate=n_layer_hp[0], layer_num=n_layer_hp[1], n_unit=n_layer_hp[2],adjust_ratio=True)\n",
    "result_dict = kfold_trainning.model_train_multiprocess()\n",
    "result =  kfold_trainning.kfold_model_evaluate_result(result_dict, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, = plot_objective(gp_fitting_n_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
